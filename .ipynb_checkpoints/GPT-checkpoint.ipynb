{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a0c678-a1f6-43e6-a3e1-6ff38cd7ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def rag_gpt():\n",
    "    \n",
    "    load_dotenv()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    context = False\n",
    "    question = \"\"\n",
    "    \n",
    "    while question != \"Exit\":\n",
    "        question = input() # Save the question of the user\n",
    "        if context == False:\n",
    "            \n",
    "            # Scraping du menu du restaurant\n",
    "            menu_to_pdf(question)\n",
    "            \n",
    "            # Connection au contexte\n",
    "            file_path = \"menu.pdf\"\n",
    "            loader = PyPDFLoader(file_path)\n",
    "\n",
    "            docs = loader.load()\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "            splits = text_splitter.split_documents(docs)\n",
    "            vectorstore = InMemoryVectorStore.from_documents(\n",
    "                documents=splits, embedding=OpenAIEmbeddings()\n",
    "            )\n",
    "\n",
    "            retriever = vectorstore.as_retriever()\n",
    "\n",
    "            # Prompt\n",
    "            system_prompt = (\n",
    "                \"You are an assistant for question-answering tasks about the menu of a specific restaurant. \"\n",
    "                \"A give you a menu, just answer my question, and don't take attention to the name that I specified. \"\n",
    "                \"Use the following pieces of retrieved context to answer \"\n",
    "                \"the question. If you don't know the answer, say that you \"\n",
    "                \"don't know. Use three sentences maximum and keep the \"\n",
    "                \"answer concise.\"\n",
    "                \"\\n\\n\"\n",
    "                \"{context}\"\n",
    "            )\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system_prompt),\n",
    "                    (\"human\", \"{input}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "            rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "            \n",
    "            context = True\n",
    "\n",
    "        if question != \"Exit\":\n",
    "            # Write an answer from the LLM\n",
    "            results = rag_chain.invoke({\"input\": question})\n",
    "    \n",
    "            # Print the answer\n",
    "            print(results[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95804958-3996-4a84-83f0-ef2266b4d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What is the menu at Esplanade ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The menu at Esplanade includes dishes like chicken peppers with mustard, homemade tomato sauce, curry of homemade vegetables, penne with homemade poultry sauce, and spinach lasagna with homemade ricotta. They also offer sides like courgettes, fries, flat carrot beans, and boulgour with spices. For dessert, they have options like brownie, cocktail of exotic fruit, and vanilla light.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What type of dessert are available ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The desserts available at Menu Esplanade include brownie, cocktail of exotic fruit, and vanilla light.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Is there some vegetable today ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are vegetable options available today such as courgettes, flat carrot beans, and a vegetable soup of the day containing carrots and celery.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Exit\n"
     ]
    }
   ],
   "source": [
    "rag_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef82fb-966f-47b3-8900-b39feab13a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9244ba-cefc-4368-95ac-9dcab835eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\busch\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\busch\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from menu_functions import menu_to_pdf\n",
    "\n",
    "def rag_gpt():\n",
    "    \n",
    "    load_dotenv(\"C:/Users/busch/OneDrive/Documents/Fac/M2/UE1 - Advanced programming and data visualization/Advanced programming/projet/environment/.env\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    context = False\n",
    "    question = \"\"\n",
    "    \n",
    "    while question != \"Exit\":\n",
    "        question = input() # Save the question of the user\n",
    "        if context == False:\n",
    "            \n",
    "            # Scraping du menu du restaurant\n",
    "            menu_to_pdf(question)\n",
    "            \n",
    "            # Connection au contexte\n",
    "            file_path = \"C:/Users/busch/OneDrive/Documents/Fac/M2/UE1 - Advanced programming and data visualization/Advanced programming/projet/dirty_file/menu.pdf\"\n",
    "            loader = PyPDFLoader(file_path)\n",
    "\n",
    "            docs = loader.load()\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "            splits = text_splitter.split_documents(docs)\n",
    "            vectorstore = InMemoryVectorStore.from_documents(\n",
    "                documents=splits, embedding=OpenAIEmbeddings()\n",
    "            )\n",
    "\n",
    "            retriever = vectorstore.as_retriever()\n",
    "\n",
    "            # Prompt\n",
    "            system_prompt = (\n",
    "                \"You are an assistant for question-answering tasks about the menu of a specific restaurant. \"\n",
    "                \"A give you a menu, just answer my question, and don't take attention to the name that I specified. \"\n",
    "                \"Use the following pieces of retrieved context to answer \"\n",
    "                \"the question. If you don't know the answer, say that you \"\n",
    "                \"don't know. Use three sentences maximum and keep the \"\n",
    "                \"answer concise.\"\n",
    "                \"\\n\\n\"\n",
    "                \"{context}\"\n",
    "            )\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system_prompt),\n",
    "                    (\"human\", \"{input}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "            rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "            \n",
    "            context = True\n",
    "\n",
    "        if question != \"Exit\":\n",
    "            # Write an answer from the LLM\n",
    "            results = rag_chain.invoke({\"input\": question})\n",
    "    \n",
    "            # Print the answer\n",
    "            print(results[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aabebc6-2087-4acf-b425-babc74aeb699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What is the menu at Esplanade ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The menu at Esplanade includes student menus on the 1st and 2nd floors with dishes like Blue cord with homemade brown sauce, Carrot duo, Fries, Curry pasta gratin, homemade vegetables, Home-made lemon-flavoured chicken casserole, Rice pilaf, Torsades with homemade carbonara sauce, and Curry of chickpeas with homemade vegetables. Desserts offered on both floors are Paris-Brest, Lemon tart, and Apple compote with speculos. In the Crystal Shop (DRC) Cafeteria, dishes like Home blue cord, Carrot duo, Curry of chickpeas with homemade vegetables, and Rice pilaf are available for on-site consumption or take-out.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What kind of dessert can I find here ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the Esplanade restaurant, you can find desserts like Paris-Brest, lemon tart, and apple compote with speculos.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Is there some vegetebale today ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are vegetable options available today, such as carrot duo, homemade vegetables, and a vegetable soup of the day with carrots and celery.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Exit\n"
     ]
    }
   ],
   "source": [
    "rag_gpt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
