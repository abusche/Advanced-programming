{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a4a2f1-91a8-4556-b330-dd0ec5305369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  # OpenAI integration for handling language models\n",
    "from langchain_core.vectorstores import InMemoryVectorStore  # In-memory storage for vectorized documents\n",
    "from langchain_openai import OpenAIEmbeddings  # OpenAI embeddings for document vectorization\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Splits text into manageable chunks\n",
    "from langchain.chains import create_retrieval_chain  # Create a chain for retrieval-based QA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain  # Combine retrieved documents for a response\n",
    "from langchain_core.prompts import PromptTemplate  # Template for formatting prompts\n",
    "from langchain.schema import Document  # Schema for representing a document\n",
    "\n",
    "import os  # Module for interacting with the operating system\n",
    "from dotenv import load_dotenv  # Load environment variables from a .env file\n",
    "from menu_functions import get_menu, detect_language, translate_text, change_context  # Custom functions for menu and language handling\n",
    "\n",
    "\n",
    "def crous():\n",
    "    # Load environment variables\n",
    "    path = \".../environment/\"\n",
    "    load_dotenv(f\"{path}.env\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "    # Prompt the user for a question\n",
    "    question = input(\"Your question: \")\n",
    "    print(question)\n",
    "    \n",
    "    history = [] # Initialize chat history\n",
    "    language = detect_language(question) # Detect the language of the user's input\n",
    "    change = True # Track if the context has changed\n",
    "\n",
    "    # Loop to handle continuous interaction until user exits\n",
    "    while question.lower() != \"exit\":\n",
    "        \n",
    "        # Add the user's question to the history\n",
    "        history.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        if change == True: # Only rebuild the context if the restaurant has changed\n",
    "            menu, restaurant_name = get_menu(question)\n",
    "            menus = translate_text(menu, language)\n",
    "            \n",
    "            # Split the menu text into smaller chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "            splits = text_splitter.split_text(menus)\n",
    "\n",
    "            # Convert each text chunk into a Document object\n",
    "            documents = [Document(page_content=split) for split in splits]\n",
    "\n",
    "            # Create an in-memory vector store for the documents\n",
    "            vectorstore = InMemoryVectorStore.from_documents(\n",
    "                documents=documents, embedding=OpenAIEmbeddings()\n",
    "            )\n",
    "            # Set up a retriever for document search\n",
    "            retriever = vectorstore.as_retriever()\n",
    "\n",
    "            # Define the system prompt for the assistant\n",
    "            system_prompt = (\n",
    "                \"You are an assistant for question-answering tasks about the menu of university restaurant. \"\n",
    "                \"If you don't specify a specific dish, you should always give today's meal or the nearest one. \"\n",
    "                \"If I ask you a question about a restaurant and you don't have the menu of this restaurant, say: 'No context'.\"\n",
    "                \"If you are unable to provide specific menu information for a restaurant for a date, say : 'No context'.\"\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"Use bullet points when it's necessary. \"\n",
    "                \"The menu will be sent to you in markdown text format. After the menu, you find the allergies part. Never show the allergen part in your answer. \"\n",
    "                \"You're also an allergy specialist. Allergies are explained in brackets. If there are allergens, you must write a message at the end, for example: ‘Warning! Allergens such as lactose or hazelnuts may be present in this menu'. \"\n",
    "                \"When I ask you about allergies, always answer about the allergies of the menu that we talked about before, never all the allergies of all menus.\"\n",
    "            )\n",
    "\n",
    "            # Create a prompt template that includes the context and user input\n",
    "            prompt_template = PromptTemplate(\n",
    "                input_variables=[system_prompt, \"input\"],\n",
    "                template=\"{context}\\n\\nHuman: {input}\"\n",
    "            )\n",
    "            # Chain to combine retrieved documents into a response\n",
    "            question_answer_chain = create_stuff_documents_chain(llm, prompt_template)\n",
    "            # Retrieval-augmented generation (RAG) chain\n",
    "            rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "        # Combine chat history into the input context\n",
    "        full_input = {\"context\": \"\\n\".join([f\"{h['role']}: {h['content']}\" for h in history]), \"input\": question}\n",
    "\n",
    "        # Invoke the chain to get an answer\n",
    "        results = rag_chain.invoke(full_input)\n",
    "\n",
    "        # Extract and translate the answer\n",
    "        answer = results.get(\"answer\")\n",
    "        translated_answer = translate_text(answer, language)\n",
    "        print(translated_answer) # Display the translated answer\n",
    "\n",
    "        # Add the assistant's answer to the history\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        # Prompt the user for the next question\n",
    "        question = input(\"Your question: \")\n",
    "        print(question)\n",
    "        change = change_context(question, restaurant_name)\n",
    "        if change == True:\n",
    "            history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c579380f-76a6-4f1a-8352-683765d8e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  Give me the menu at Le PEGE for the lunch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the menu at Le PEGE for the lunch\n",
      "Certainly! Here's the lunch menu for Monday, January 13, 2025, at Le PEGE:\n",
      "\n",
      "**Daily Specials:**\n",
      "1. **Cordon Bleu with Dry-Cured Ham & Comté Cheese** - Served with pan-fried yellow carrots & sweet potato. Choice of homemade spaetzle or fries.\n",
      "2. **Turkey Cordon Bleu** - Served with pan-fried yellow carrots & sweet potato. Choice of homemade spaetzle or fries.\n",
      "\n",
      "**Vegetarian Option:**\n",
      "- **Spaetzle Gratin** - Served with braised cabbage & Munster cheese and a mushroom sauce.\n",
      "\n",
      "**Allergens:**\n",
      "- Coffee & Pastries: Gluten, Eggs, Lactose\n",
      "- Cordon Bleu with Dry-Cured Ham & Comté Cheese: Gluten, Eggs, Lactose\n",
      "- Turkey Cordon Bleu: Gluten, Eggs, Lactose\n",
      "- Homemade Spaetzle or Fries: Gluten, Eggs, Lactose, Nut\n",
      "- Spaetzle Gratin: Lactose\n",
      "- Braised Cabbage & Munster Cheese: Lactose\n",
      "- Mushroom Sauce: Lactose, Nut\n",
      "\n",
      "Enjoy your lunch at Le PEGE!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  What can I find at Esplanade for the diner ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can I find at Esplanade for the diner ?\n",
      "For dinner at Esplanade on Monday, January 13, 2025, you can enjoy the following menu items on the 1st floor:\n",
      "\n",
      "**Main Courses:**\n",
      "- Beef fricadelle with cream sauce\n",
      "- Green beans\n",
      "- Roasted potatoes\n",
      "- Arrabiata pasta gratin\n",
      "\n",
      "**Desserts:**\n",
      "- Paris-Brest\n",
      "- Lemon tart\n",
      "- Apple compote with speculoos\n",
      "\n",
      "**Allergens Information:**\n",
      "- Beef fricadelle contains gluten, eggs, and nuts.\n",
      "- Cream sauce contains eggs and lactose.\n",
      "- Roasted potatoes contain lactose.\n",
      "- Arrabiata pasta gratin contains gluten and lactose.\n",
      "- Paris-Brest contains gluten, eggs, lactose, and nuts.\n",
      "- Lemon tart contains gluten, eggs, and lactose.\n",
      "- Apple compote with speculoos contains lactose.\n",
      "\n",
      "Please be mindful of the allergens in each dish if you have dietary restrictions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  What is Arrabiata pasta gratin ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Arrabiata pasta gratin ?\n",
      "Arrabiata pasta gratin is a dish that consists of pasta baked with Arrabiata sauce and usually topped with cheese. Arrabiata sauce is a spicy sauce made from tomatoes, garlic, and dried red chili peppers cooked in olive oil. The sauce originates from Italy and is known for its bold, spicy flavor. In a gratin version, the pasta and Arrabiata sauce are typically mixed together, topped with a layer of cheese such as mozzarella or Parmesan, and then baked in the oven until the cheese is golden and bubbly. This dish combines the heat of the Arrabiata with the comforting, creamy texture of the baked cheese topping.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  Give me a dish without milk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a dish without milk\n",
      "For a dish without milk (lactose) from the student menu on the 1st floor at Esplanade for dinner on Monday, January 13, 2025, you can choose the following options:\n",
      "\n",
      "- Beef fricadelle (Note: contains gluten, eggs, and nuts)\n",
      "- Green beans\n",
      "- Roasted potatoes (Note: while it contains lactose, you can request it without butter or any milk-based products if possible)\n",
      "\n",
      "For dessert, the options without milk are limited. It seems all desserts listed contain lactose. You might need to inquire if there is an alternative dessert option available without milk.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit\n"
     ]
    }
   ],
   "source": [
    "crous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
